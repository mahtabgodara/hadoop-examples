how to share ssh keys with password?
when does the hadoop configuration changes take place?


Setting up cssh 
http://www.nextstep4it.com/categories/how-to/cssh/
#on Master
sudo apt-get install clusterssh

training@master:~$ cssh -l root slave1 slave2
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LANGUAGE = (unset),
	LC_ALL = (unset),
	LC_CTYPE = "UTF-8",
	LANG = "en_US.UTF-8"
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
Can't open /home/training/.Xauthority: Permission denied at /usr/share/perl5/X11/Protocol.pm line 2303.

export LANGUAGE=en_US.UTF-8
export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8
locale-gen en_US.UTF-8
sudo dpkg-reconfigure locales

# On CentOS
groupadd hadoop
useradd -G hadoop hduser
id hduser
visudo
hduser	ALL=(ALL)	ALL

#on all machines
sudo addgroup hadoop
sudo adduser --ingroup hadoop hduser
sudo usermod -a -G sudo hduser

#On master node
su - hduser
ssh-keygen -t rsa -P ""
cat /home/hduser/.ssh/id_rsa.pub >> /home/hduser/.ssh/authorized_keys
ssh-copy-id -i /home/hduser/.ssh/id_rsa.pub hduser@slave1
ssh-copy-id -i /home/hduser/.ssh/id_rsa.pub hduser@slave2

#on all nodes
touch ~/.Xauthority  #to resolve the X11 forwarding error
grep X11Forwarding /etc/ssh/sshd_config  # X11Forwarding must be enabled

#On master
cssh -l hduser master slave1 slave2


mkdir softwares
cd softwares
wget http://mirror.reverse.net/pub/apache/hadoop/common/hadoop-1.2.1/hadoop-1.2.1-bin.tar.gz
tar xvzf hadoop-1.2.1-bin.tar.gz
sudo ln -s /home/hduser/softwares/hadoop-1.2.1 /usr/local/hadoop


which javac
ls -l /usr/bin/javac
ls -l /etc/alternatives/javac
# JAVA HOME is /usr/lib/jvm/java-6-openjdk-amd64/

vi ~/.bashrc 
#Append the following 
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64/
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin


# save and exit
source ~/.bashrc

cd /usr/local/hadoop
hadoop jar hadoop-examples-1.2.1.jar wordcount README.txt out.0 
rm -rf ./out.0

# disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1

# In conf/hadoop-env.sh
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true

vi conf/hadoop-env.sh

export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64/
export HADOOP_HEAPSIZE=1000

conf/core-site.xml

sudo mkdir -p /app/hadoop/tmp
sudo chown hduser:hadoop /app/hadoop/tmp
# ...and if you want to tighten up security, chmod from 755 to 750...
sudo chmod 750 /app/hadoop/tmp

vi conf/core-site.xml

<property>
  <name>hadoop.tmp.dir</name>
  <value>/app/hadoop/tmp</value>
  <description>A base for other temporary directories.</description>
</property>

<property>
  <name>fs.default.name</name>
  <value>hdfs://localhost:9000</value>
  <description>The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.</description>
</property>


vi conf/mapred-site.xml

<property>
  <name>mapred.job.tracker</name>
  <value>localhost:9001</value>
  <description>The host and port that the MapReduce job tracker runs
  at.  If "local", then jobs are run in-process as a single map
  and reduce task.
  </description>
</property>


vi conf/hdfs-site.xml

<property>
  <name>dfs.replication</name>
  <value>1</value>
  <description>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  </description>
</property>


#On Master

hadoop namenode -format

start-dfs.sh
jps on each blade

start-mapred.sh
jps on each blade

hadoop dfsadmin -report

hadoop fs operations can be performed now

hadoop fsck / -files -blocks


prepare the new node
Commissioning a new node

vi conf/hdfs-site.xml
<property>
<name>dfs.hosts</name>
<value>/usr/local/hadoop/conf/includes</value>
<final>true</final>
</property>

add the node to /etc/hosts of all the nodes
add the node to slaves file

hadoop dfsadmin -refreshNodes
hadoop mradmin -refreshNodes

On the new node 
hadoop-daemon.sh start tasktracker
hadoop-daemon.sh start datanode

jps

On Master
hadoop dfsadmin -report
wget http://dumps.wikimedia.org/other/pagecounts-raw/2014/2014-01/pagecounts-20140101-000000.gz
gunzip pagecounts-20140101-000000.gz
hadoop dfs -put pagecounts-20140101-000000 pagecounts-20140101-000000
start-balancer.sh

hadoop fsck /user/hduser/pagecounts-20140101-000000 -files -blocks -locations


To add new nodes to the cluster:
1. Add the network addresses of the new nodes to the include file.
2. Update the namenode with the new set of permitted datanodes using this command:
% hadoop dfsadmin -refreshNodes
3. Update the jobtracker with the new set of permitted tasktrackers using:
% hadoop mradmin -refreshNodes
4. Update the slaves file with the new nodes, so that they are included in future op-
erations performed by the Hadoop control scripts.
5. Start the new datanodes and tasktrackers.
6. Check that the new datanodes and tasktrackers appear in the web UI.




Decommision should be easier
vi conf/hdfs-site.xml
<property>
<name>dfs.hosts.excludes</name>
<value>/usr/local/hadoop/conf/excludes</value>
<final>true</final>
</property>

mapred-site.xml

<property>
<name>mapred.hosts.exclude</name>
<value>/usr/local/hadoop/conf/excludes</value>
<final>true</final>
</property>

vi /usr/local/hadoop/conf/excludes
slave3
hadoop dfsadmin -refreshNodes
vi /usr/local/hadoop/conf/includes
remove slave3
hadoop dfsadmin -refreshNodes

vi conf/slaves
remove slave3


To remove nodes from the cluster:
1. Add the network addresses of the nodes to be decommissioned to the exclude file. Do not update the include file at this point.
2. Update the namenode with the new set of permitted datanodes, with this command:
% hadoop dfsadmin -refreshNodes
3. Update the jobtracker with the new set of permitted tasktrackers using:
% hadoop mradmin -refreshNodes
4. Go to the web UI and check whether the admin state has changed to “Decommis- sion In Progress” for the datanodes being decommissioned. They will start copying their blocks to other datanodes in the cluster.
5. Whenallthedatanodesreporttheirstateas“Decommissioned,”thenalltheblocks have been replicated. Shut down the decommissioned nodes.
6. Remove the nodes from the include file, and run:
% hadoop dfsadmin -refreshNodes
% hadoop mradmin -refreshNodes
7. Remove the nodes from the slaves file.




On Master

cd ~/softwares
wget http://mirror.reverse.net/pub/apache/hive/stable/apache-hive-0.13.1-bin.tar.gz
tar xvzf apache-hive-0.13.1-bin.tar.gz
ln -s apache-hive-0.13.1-bin /usr/local/hive

vi ~/.bashrc
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin

source ~/.bashrc

Hive uses Hadoop, so:

    you must have Hadoop in your path OR
    export HADOOP_HOME=<hadoop-install-dir>

In addition, you must create /tmp and /user/hive/warehouse (aka hive.metastore.warehouse.dir) and set them chmod g+w in HDFS before you can create a table in Hive.

Commands to perform this setup:

  $ $HADOOP_HOME/bin/hadoop fs -mkdir       /tmp
  $ $HADOOP_HOME/bin/hadoop fs -mkdir       /user/hive/warehouse
  $ $HADOOP_HOME/bin/hadoop fs -chmod g+w   /tmp
  $ $HADOOP_HOME/bin/hadoop fs -chmod g+w   /user/hive/warehouse

You may find it useful, though it's not necessary, to set HIVE_HOME:

  $ export HIVE_HOME=<hive-install-dir>

To use the Hive command line interface (CLI) from the shell:

  $ $HIVE_HOME/bin/hive


vi emps.txt
A|20
B|30
C|10
D|40

https://hive.apache.org/javadocs/hcat-r0.5.0/loadstore.html
http://www.javawhat.com/showWebsiteContent.do?id=528018
  
export METASTORE_PORT=9050
bin/hive --service metastore &
netstat -an | grep 9050
hcatalog/sbin/hcat_server.sh start 
hcatalog/sbin/webhcat_server.sh start
hcatalog/bin/hcat -e "create table employees ( name STRING, age INT) row format delimited fields terminated by '|'"
hadoop fs -put emps.txt /user/hive/warehouse/employees/
hive -e "select * from employees"

Running Pig with HCatalog

The -useHCatalog Flag
pig -useHCatalog

vi ~/.bashrc

export HADOOP_HOME=<path_to_hadoop_install>

export HCAT_HOME=<path_to_hcat_install>

export HIVE_HOME=<path_to_hive_install>

export PIG_CLASSPATH=$HCAT_HOME/share/hcatalog/hcatalog-*.jar:\
$HIVE_HOME/lib/hive-metastore-*.jar:$HIVE_HOME/lib/libthrift-*.jar:\
$HIVE_HOME/lib/hive-exec-*.jar:$HIVE_HOME/lib/libfb303-*.jar:\
$HIVE_HOME/lib/jdo2-api-*-ec.jar:$HIVE_HOME/conf:$HADOOP_HOME/conf:\
$HIVE_HOME/lib/slf4j-api-*.jar

export PIG_OPTS=-Dhive.metastore.uris=thrift://<hostname>:<port>


A = LOAD 'tablename' USING org.apache.hcatalog.pig.HCatLoader(); 
dump A

HCatStorer

HCatStorer is used with Pig scripts to write data to HCatalog-managed tables.

Usage

HCatStorer is accessed via a Pig store statement.

A = LOAD ...
B = FOREACH A ...
...
...
my_processed_data = ...

STORE my_processed_data INTO 'tablename'
   USING org.apache.hcatalog.pig.HCatStorer();





